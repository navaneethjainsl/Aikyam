# -*- coding: utf-8 -*-
"""asl-words.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QTpwVFcpFp6zBBNRNzBxGn4qSszf459b
"""

# from google.colab import drive
# drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import json

data = pd.read_csv('/kaggle/input/asl-words-keypoints/keypoints_words.csv',header=None)

data[0] = data[0].astype(str)

data[0].unique()

X = data.iloc[:,1:]
X

enc = LabelEncoder()

y = enc.fit_transform(data[[0]])
y

print(y)

from keras.callbacks import EarlyStopping
es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42)

model = keras.Sequential([
    layers.Dense(1470, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(832, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(428, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(264, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(35, activation='softmax'),
    # layers.Dense(len(data[0].unique()), activation='softmax')  # Output layer (matches word count)
])

model.compile(loss = "sparse_categorical_crossentropy", optimizer = "adam", metrics=["accuracy"])

model.fit(X_train, y_train, epochs = 50, batch_size = 128, validation_split = 0.2, callbacks=[es])

model.evaluate(X_test, y_test, verbose = 0)

# evaluate the model on the validation set and compute performance metrics
y_val_pred = model.predict(X_test)
y_val_pred_classes = np.argmax(y_val_pred, axis=1)
acc = accuracy_score(y_test, y_val_pred_classes)
prec = precision_score(y_test, y_val_pred_classes, average='macro')
rec = recall_score(y_test, y_val_pred_classes, average='macro')
f1 = f1_score(y_test, y_val_pred_classes, average='macro')
print("Accuracy:", acc)
print("Precision:", prec)
print("Recall:", rec)
print("F1-score:", f1)

model.save("model.h5")